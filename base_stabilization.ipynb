{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the video input\n",
    "vid = cv2.VideoCapture('./test.avi')\n",
    "\n",
    "# Get the frame count\n",
    "n_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Width and height of each frame\n",
    "w = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# FPS\n",
    "fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Set up output\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "# Output format\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter('test_out.mp4', fourcc, fps, (w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read first frame\n",
    "_, prev = vid.read()\n",
    "\n",
    "# Convert to Grayscale\n",
    "prev_gray = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the transformation matrix\n",
    "transforms = np.zeros((n_frames - 1, 3), np.float32)\n",
    "\n",
    "for i in range(n_frames - 1):\n",
    "    # Feature points of the previous frame\n",
    "    # The feature points are obtained using the Shi-Tomasi corner detection algorithm\n",
    "    prev_pts = cv2.goodFeaturesToTrack(prev_gray, maxCorners=200, qualityLevel=0.01, minDistance=30, blockSize=3)\n",
    "\n",
    "    # Read the next frame, if it doesn't exist, exit the loop\n",
    "    flag, frame = vid.read()\n",
    "    if not flag:\n",
    "        break\n",
    "\n",
    "    # Convert to Grayscale\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate the Optical flow using the Lucas-Kanade method\n",
    "    frame_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prev_pts, None)\n",
    "\n",
    "    # Sanity check\n",
    "    assert frame_pts.shape == prev_pts.shape\n",
    "\n",
    "    # Only store the valid pts\n",
    "    idx = np.where(status == 1)[0]\n",
    "    prev_pts = prev_pts[idx]\n",
    "    frame_pts = frame_pts[idx]\n",
    "\n",
    "    # Obtain the transformation matrix\n",
    "    mat = cv2.estimateAffine2D(prev_pts, frame_pts)[0]\n",
    "\n",
    "    # Translation components\n",
    "    dx = mat[0][2]\n",
    "    dy = mat[1][2]\n",
    "\n",
    "    # Rotation component\n",
    "    dtheta = np.arctan2(mat[1, 0], mat[0, 0])\n",
    "\n",
    "    # Store the components corresponding to each frame\n",
    "    transforms[i] = [dx ,dy, dtheta]\n",
    "\n",
    "    # Store the current frame\n",
    "    prev_gray = frame_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the trajectory as a cumulative sum of the dx, dy and dtheta components\n",
    "trajectory = np.cumsum(transforms, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving average filter\n",
    "def mav_filter(curve, radius):\n",
    "    window_size = 2*radius + 1\n",
    "    filter = np.ones(window_size) / window_size\n",
    "    # Padding\n",
    "    curve_padded = np.lib.pad(curve, (radius, radius), 'edge')\n",
    "    curve_smooth = np.convolve(curve_padded, filter, mode='same')\n",
    "    # Remove padding\n",
    "    curve_output = curve_smooth[radius:-radius]\n",
    "\n",
    "    return curve_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothen the trajectory\n",
    "def smooth(trajectory, radius=7):\n",
    "    trajectory_smooth = np.copy(trajectory)\n",
    "\n",
    "    for i in range(3):\n",
    "        trajectory_smooth[:, i] = mav_filter(trajectory[:, i], radius)\n",
    "\n",
    "    return trajectory_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the smooth trajectory\n",
    "trajectory_smooth = smooth(trajectory)\n",
    "\n",
    "# Compute the difference in trajectories\n",
    "trajectory_difference = trajectory_smooth - trajectory\n",
    "\n",
    "# Obtain the new transformation components\n",
    "transforms_smooth = transforms + trajectory_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the border by scaling the image about its center\n",
    "def fix_border(frame):\n",
    "    n = frame.shape\n",
    "    T = cv2.getRotationMatrix2D((n[1]/2, n[0]/2), 0, 1.04)\n",
    "    frame_out = cv2.warpAffine(frame, T, (n[1], n[0]))\n",
    "\n",
    "    return frame_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset stream to first frame\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# Transform the frame using the new transformation components to obtain the stabilized frame\n",
    "for i in range(n_frames - 1):\n",
    "    flag, frame = vid.read()\n",
    "    if not flag:\n",
    "        break\n",
    "\n",
    "    # Transformation components for the current matrix\n",
    "    dx = transforms_smooth[i, 0]\n",
    "    dy = transforms_smooth[i, 1]\n",
    "    dtheta = transforms_smooth[i, 2]\n",
    "    \n",
    "    # Construct the transformation matrix\n",
    "    mat = np.zeros((2, 3), np.float32)\n",
    "    mat[0, 0] = np.cos(dtheta)\n",
    "    mat[0, 1] = -np.sin(dtheta)\n",
    "    mat[1, 0] = np.sin(dtheta)\n",
    "    mat[1, 1] = np.cos(dtheta)\n",
    "    mat[0, 2] = dx\n",
    "    mat[1, 2] = dy\n",
    "\n",
    "    # Apply the transformation\n",
    "    frame_stabilized = cv2.warpAffine(frame, mat, (w, h))\n",
    "    frame_stabilized = fix_border(frame_stabilized)\n",
    "\n",
    "    # Write to file\n",
    "    frame_out = cv2.hconcat([frame, frame_stabilized])\n",
    "\n",
    "    # If too big, resize\n",
    "    if(frame_out.shape[1] > 1920):\n",
    "        frame_out = cv2.resize(frame_out, (w, h))\n",
    "    \n",
    "    cv2.imshow('frame', frame_out)\n",
    "    cv2.waitKey(10)\n",
    "    out.write(frame_out)\n",
    "\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
